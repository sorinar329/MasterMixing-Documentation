\chapter{Conclusion}
\label{chap:conclusion}

\section{Summary}
This master's thesis serves as a proof of concept to demonstrate how a robotic system like the PR2, utilizing the cognitive architecture CRAM, can make knowledge-based decisions and perform mixing actions in a simulation.

In order to implement the motions in CRAM, one must first understand the relationship of the motions to the overall context of the task the robot needs to solve. What we have discovered is that the motions are primarily dependent on the ingredients in the context of mixing tasks. The containers and tools used do not directly influence the motion itself, but they do modify the action range of the motions.

The model we use—a knowledgebase—captures various important aspects of a mixing action. It includes information about the ingredients being mixed, the types of motions that can be performed, the type of container used for storing and mixing ingredients, and the tools needed for mixing. By keeping the model simple, we ensure that the robot can infer motions using the rule-based language SWRL.

Our modeled motions do not specify how a motion is executed but provide capabilities via parameters to adapt to different containers and tools. The implementation of each motion—\textbf{Circular}, \textbf{Folding}, \textbf{Horizontal Elliptical}, and \textbf{Whirlstorm}—is available in pycram, and any robotic system that can use \textit{Cram} can perform these motions.

In addition to this proof of concept, we developed a new way to visualize ontologies by focusing on complex class expressions, which hasn't been done before. With the \textit{OWLVisualizer}, a user can query complex class expressions without needing to know how to write \textit{SPARQL} queries. The \textit{OWLVisualizer} generates a \textit{SPARQL} query for the user, using triple matching to get the desired graph. This query can be customized by changing its contents without altering the triple matching.


To conclude our master thesis, we want to give a brief overview of our workflow.
Initially, the focus was on data acquisition, primarily conducted through video analyses of various cooking videos. In this phase, we also examined the meaning of the term \textit{mixing} and its variations to establish a robust data foundation.

Following data acquisition, we turned our attention to the modeling and structuring of the knowledge base. This involved defining our classes, including motions and their associated parameters.

In the next section, we transitioned from theory to practice by applying the defined classes in a simulation. As a proof of concept, we tested as many scenarios as possible to demonstrate how the knowledge base we created could be applied to a robot.

Finally, we introduced a new framework designed for visualizing graphs. This framework boasts several features, such as an integrated query and inference builder.
- Data aqcuired and Structured.
- Modelled a queryable Knowledgebase
- Adapted motions
- Proof Of Concept
- Graphviz
\section{Future Work}
This proof of concept was established in \textit{Cram} in simulation. In simulations many things are simple.
The robot has ground truth for each available object, the ingredients to mix, the tools to perform mixing, the container to mix in. 
To move ahead, our proof of concept should be implemented on a real robot, to see how much more difficult it will 
be in real world scenarios.

With regards to future work many limitations arose during implementation of our proof of concept.
Our motions are effectively 2D motions, where one axis is not changing over the course of the motion.
Moving from simulation to real world, it will be necessary to include dives into each motion, so that 
the substances are properly mixed. 

Another limiting aspect is the lack of collision detection. As of now, we ensure that the tool is not colliding 
with objects only with respect to 2 out of 3 axes. If the tool is placed to low, and the container has a spherical shape and not 
cuboid shape, the tool will eventually collide with the object. To tackle this limitation, we require depth-based perception
and various techniques to find out optimal height for the tool during execution of a mixing action.

Once we move to real world we loose ground truth on all relevant objects required for mixing.
Here we will need perception frameworks capable of detecting and locating objects in a scene, 
picking and placing objects and different kinds of actions for example pouring, to fill a container
with ingredients.

In simulation the robot will not fail unless the inference fails. As long as a motion is inferred, mixing will be executed.
This has to be adjusted



- Diving motions
- Prediction substances
- Deployment on real robot
- Uncertainity. -> Object Detection
- Failure Handling

\section{Last Words}

- GEOMETRIE IN EINLEITUNG BETRACHTEN.
keine fragen in EINLEITUNG